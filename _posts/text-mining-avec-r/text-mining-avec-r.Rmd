---
title: "Text Mining avec R"
description: |
  Le Text Mining consiste √† utiliser le Machine Learning pour l‚Äôanalyse de texte. D√©couvrez tout ce que vous devez savoir : d√©finition, fonctionnement, techniques, avantages, cas d‚Äôusage‚Ä¶. 
author:
  - name: Ousmane Ouedraogo
    url: https://ousmane-ouedraogo.netlify.app
date: 2021-12-06
categories: 
  - TEXT MINING
  - TIDYVERSE
  - VISUALISATION
output:
  distill::distill_article:
    self_contained: false
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, message = FALSE, warning = FALSE,
  fig.width = 15,
  fig.height = 10, fig.retina = 2,
  dev = "ragg_png", res = 1000
)
```

## Introduction

Le text mining (√©galement connue sous le nom d'analyse de texte) est le processus de transformation de texte non structur√© en donn√©es structur√©es pour une analyse facile. L'exploration de texte utilise le traitement du langage naturel (ou Natural Language Processing en anglais -NLP), permettant aux machines de comprendre le langage humain et de le traiter. En effet l'exploration de texte automatise le processus de classification des textes par sentiment, sujet et intention. Cet article va introduire la notion de texte mining, √©numerer quelques m√©thodes et proposer une mise oeuvre simple avec le logiciel R.

## Les techniques du Text Mining

Il existe diff√©rentes m√©thodes et techniques de text mining. Dans cette section, nous allons couvrir certains des plus fr√©quents. De fa√ßon globale l'analyse de texte, suit le workflow ci-apr√®s d√©fini dans [Text Mining with R : A Tidy Approach](https://www.tidytextmining.com/tidytext.html "tidytextmining"). Un ouvrage exc√©llent pour aller plus loin dans le text mining.

![A flowchart of a typical text analysis using tidy data principles](images/tmwr_0101.png "Tidy text mining")

### La fr√©quence des mots

La fr√©quence des mots peut √™tre utilis√©e pour identifier les termes ou concepts les plus r√©currents dans un ensemble de donn√©es. Trouver les mots les plus mentionn√©s dans un texte non structur√© peut √™tre particuli√®rement utile lors de l'analyse des avis des clients, des conversations sur les r√©seaux sociaux ou de discours.

### La collocation

La collocation fait r√©f√©rence √† une s√©quence de mots qui apparaissent g√©n√©ralement les uns √† c√¥t√© des autres. Les types de collocations les plus courants sont les bigrammes (une paire de mots susceptibles d'aller ensemble, comme d√©marrer, gagner du temps ou prendre une d√©cision) et les trigrammes (une combinaison de trois mots, comme √† distance de marche ou rester en contact).

Identifier les collocations - et les compter comme un seul mot - am√©liore la granularit√© du texte, permet une meilleure compr√©hension de sa structure s√©mantique et, au final, conduit √† des r√©sultats de text mining plus pr√©cis.

### L'analyse de sentiment

Elle consiste √† analyser les √©motions qui sous-tendent un texte donn√©. Supposons que vous analysiez une un feedback client sur votre application mobile. Vous d√©couvrirez peut-√™tre que les sujets les plus fr√©quemment mentionn√©s dans ces revues sont la convivialit√© ou la facilit√© d'utilisation, mais ce n'est pas assez d'informations pour tirer des conclusions. L'analyse des sentiments vous aide √† comprendre l'opinion et les sentiments dans un texte et √† les classer comme positifs, n√©gatifs ou neutres. L'analyse des sentiments a de nombreuses applications utiles. En effet, elle peut se reveler un r√©el atout en support client, en proposition de services bas√©s sur retour utilisateur ou simplement appr√©hender la tendance g√©n√©rale d'un discours.

## Reproductibilit√©

Dans cette section se trouve tout ce dont vous avez besoin pour reproduire les diff√©rentes analyses sur votre ordinateur.

### Package R

Les diff√©rents packages dont nous aurons besoin sont les suivants :

```{r}
library(tidytext) # CRAN v0.3.2
library(rfeel) # [github::ColinFay/rfeel] v0.0.0.9000
library(proustr) # CRAN v0.4.0
library(tidyverse) # CRAN v1.3.1
library(pilot) # [github::olihawkins/pilot] v3.5.0
library(extrafont) # CRAN v0.17
library(readr) # CRAN v2.1.0
library(wordcloud) # CRAN v2.6
loadfonts()
```

### Donn√©es

Les donn√©es √† utiliser devant √™tre textuelles,nous avons r√©cuperer [ici](https://www.thomassankara.net/wp-content/uploads/2005/09/Discours_orientation_politique.pdf "DOP-1983") le Discours d'Orientation Politique (DOP) prononc√© le 02 Octobre 1983 par le Capitaine Thomas Sankara. Le discours √† √©t√© copier dans un fichier texte.

### Th√®me g√©n√©ral des plots

```{r}
theme_set(new = theme_pilot(
  title_size = 30, subtitle_size = 25,
  caption_size = 20, axis_text_size = 25, axis_title_size = 25
))
```

## Import et traitement des donn√©es

### Import et formatage

Dans cette section, nous allons importer le discours d'orientation politique dans R et le formater selon le principe du tidy text data.

```{r}
dop_speech <- read_lines(
  file = "../../data/dop_02_oct_thomas_sankara.txt"
) %>%
  tibble(line = 1:179, text = .)
```

### Tok√©nisation du texte

Nous avons √† pr√©sent pour, 179 lignes de textes. Pour le moment il est difficile de travailler ce texte. Il va falloir d√©composer les lignes de textes en "tokens". Un token est une unit√© de texte significative, le plus souvent un mot, que nous souhaitons utiliser pour une analyse plus approfondie, et la "tokenisation" est le processus de division du texte en "tokens".

Pour ce faire, nous utiliserons la fonction `unnest_tokens()` du package tidytext.

```{r}
dop_speech %>%
  unnest_tokens(word, text)
```

Apr√®s avoir utilis√© la fonction `unnest_tokens()`, nous avons divis√© chaque ligne de mani√®re √† ce qu'il y ait un token (mot) dans chaque ligne de la nouvelle table de donn√©es¬†; la tok√©nisation par d√©faut dans `unnest_tokens()` concerne les mots simples (pas compos√©s), comme indiqu√© ici. Vous pouvez √©galement notez que¬†:

-   Les autres colonnes, telles que le num√©ro de ligne d'o√π provient chaque mot, sont conserv√©es.

-   La ponctuation a √©t√© supprim√©e.

Par d√©faut, unnest_tokens() convertit les tokens en minuscules, ce qui les rend plus faciles √† comparer ou √† combiner avec d'autres ensembles de donn√©es.

Avoir les donn√©es de texte dans ce format nous permet de manipuler, de traiter et de visualiser le texte √† l'aide de l'√©cosyst√®me tidyverse.

### N√©ttoyer les mots vides ou stopwords

Maintenant que les donn√©es sont au format un mot par ligne, nous pouvons les manipuler avec des outils du tidyverse comme dplyr. Souvent dans l'analyse de texte, nous voudrons supprimer les mots vides ( des sens ); Les mots vides sont des mots qui ne sont pas utiles pour une analyse, g√©n√©ralement des mots extr√™mement courants tels que ¬´¬†le¬†¬ª, ¬´¬†de¬†¬ª, ¬´¬†√†¬†¬ª, et ainsi de suite. Nous pouvons les supprim√©s de notre jeux de donn√©es. Pour cela nous allons utiliser la base de donn√©es stop_words contenu dans le package [proustr](https://colinfay.me/proustr-package/).

```{r}
dop_speech_clean <- dop_speech %>%
  unnest_tokens(word, text) %>%
  anti_join(x = ., stop_words)
```

On passe alors de plus de 10 000 mots √† quelques 5200, apr√®s nettoyage des mots vides !

Nous avons en plus de ces mots, du texte num√©rique que nous devons nettoyer . Nous utiliserons le regex pour les supprimer.

Ici le code permet de les retrouver.

```{r}
num_val <- dop_speech_clean %>%
  pull("word") %>%
  grep(pattern = "[0-9]", x = ., value = TRUE)
head(num_val)
```

Une fois les nombres retrouver, nous proc√©derons √† leur suppression. Le mot "√†" est tout de m√™me contenu dans notre texte, . Il faut noter que les textes en fran√ßais sont plus difficiles √† analyser : accents, apostrophes et pleins de caract√®res sp√©ciaux, et m√™me l'encodage pose des fois probl√®mes. Nous ferons avec üòÖ.

```{r}
dop_speech_clean <- dop_speech_clean %>%
  filter(!(word %in% num_val), word != word[84])
```

## Analyse et visualisation du texte

Dans cette question il sera question d'analyser le texte √† proprement parler. Quels sont les mots utilis√©s de fa√ßon fr√©quence, leur polarit√© (positif ou n√©gatif) ainsi que le sentiment g√©n√©rale d√©gag√© par le texte (joie, tristesse etc..). Il est important de garder √† l'esprit que nous sommes en introduction et qu'il est plus approprier pour un linguiste, un communicateur de tirer de meilleures informations. A la base je ne poss√®de pas ses comp√©tences.

### Fr√©quence des mots

Comme dit plus haut, une des m√©thodes d'analyses du texte consiste √† √©labor√© une table de fr√©quence de ceux. concr√®tement il s'agira pour chaque mot de compter combien de fois il a √©t√© utilis√© dans le texte. Le package dplyr offre d'importantes facilit√©s pour y arriver.

```{r}
dop_speech_clean %>%
  count(word, sort = TRUE, name = "freq")
```

Un aper√ßu rapide indique que le mot le plus fr√©quent dans ce discours est peuple suivi loin derri√®re par pays. Il d√©meurre des soucis avec "√†","d'une" etc.. que je ne saurais expliquer √† l'√©tape actuelle. Comme pour dire que l'analyse de texte est un travail fastidieux et n√©cessite de la minutie. Dans cet article nous les supprimerons. Bien entendu nous perdons de l'information. Nous reviendrons dans un autre article sur comment nettoyer, filtrer du texte avec regex (regular expressions.)

Les dix mots les plus fr√©quents :

```{r}
word_freq <- dop_speech_clean %>%
  count(word, sort = TRUE, name = "freq") %>%
  filter(!(word %in% c("aÃÄ", "d'une"))) %>%
  top_n(10)

word_freq %>%
  kableExtra::kable(format = "markdown")
```

Une visualisation rapide :

```{r , preview = TRUE}
word_freq %>%
  mutate(word = reorder(word, freq)) %>%
  ggplot(mapping = aes(x = word, y = freq)) +
  geom_col() +
  coord_flip() +
  labs(
    x = NULL, y = "# Nombre",
    title = "Le Discours d'Orientation Politique en mots",
    subtitle = "Thomas Sankara | Octobre 1983 ",
    caption = " ¬© Data Science avec R, 2021"
  ) +
  theme(plot.title.position = "plot")
```

### Connotation des mots

Une autre technique d'analyse de donn√©es textuelles consiste √† d√©terminer si un mot √† une connotation positive ou n√©gative et de trouver une mani√®re √©l√©gante de visualiser tout cela.

La connotation (positive ou n√©gative ) des mots en fran√ßais est consign√©e dans la base de donn√©es du package [rfeel](https://github.com/ColinFay/rfeel "rfeel").

```{r}
connotation <- dop_speech_clean %>%
  inner_join(x = ., y = rfeel("polarity")) %>%
  group_by(polarity) %>%
  count(word, polarity, sort = TRUE, name = "freq") %>%
  slice_max(freq, n = 10) %>% # 10 pour un barchart
  ungroup()
```

Barchart:

```{r}
connotation %>%
  mutate(word = reorder(word, freq)) %>%
  ggplot(mapping = aes(x = word, y = freq, fill = polarity)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~polarity, scales = "free_y") +
  labs(
    x = NULL, y = "# Nombre",
    title = "Connotation g√©n√©rale du Discours d'Orientation Politique",
    subtitle = "Thomas Sankara | Octobre 1983",
    caption = "¬© Data Science avec R, 2021"
  ) +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 25, hjust = .5),
    plot.title.position = "plot"
  )
```

D'une mani√®re g√©n√©rale, le discours d√©gage une connotation positive.

### Wordcloud ou nuage de mots

Un **nuage de mots**¬†n'est ni plus ni moins qu'une¬†**repr√©sentation visuelle**¬†permettant :

-   d'**identifier rapidement les mots cl√©s**¬†pr√©sentant le plus d'occurrences dans un texte (plus un mot appara√Æt fr√©quemment, plus la taille de la police dans le nuage de mots est grande)

-   de¬†**faciliter la compr√©hension**¬†d'un texte

-   de¬†**rep√©rer rapidement les id√©es principales**¬†d'un texte en faisant appara√Ætre les champs lexicaux pr√©sents dans ce dernier.

Impl√©mentation dans R:

```{r, fig.width=10,fig.height=6}
set.seed(123)
dop_speech_clean %>%
  filter(!(word %in% c("aÃÄ", "d'une"))) %>%
  count(word) %>%
  with(wordcloud(
    words = word, freq = n, max.words = 100,
    random.order = FALSE, min.freq = 15
  ))
```

Voil√† un joli nuage de mots issu du discours d'orientation politique. Nous pouvons le parfaire en ajoutant une touche de couleur.

```{r, fig.width=10,fig.height=6}
set.seed(123)
pal <- brewer.pal(8, "Dark2")
dop_speech_clean %>%
  filter(!(word %in% c("aÃÄ", "d'une"))) %>%
  count(word) %>%
  with(wordcloud(
    words = word, freq = n, max.words = 100,
    random.order = FALSE, min.freq = 15,
    colors = pal
  ))
```

Un autre wordcloud avec la connotation (positive ou n√©gative) :

```{r, fig.width=10,fig.height=6}
set.seed(123)

library(reshape2)

dop_speech_clean %>%
  inner_join(x = ., y = rfeel("polarity")) %>%
  group_by(polarity) %>%
  count(word, polarity, sort = TRUE, name = "freq") %>%
  acast(word ~ polarity, value.var = "freq", fill = 0) %>%
  comparison.cloud(
    colors = c("gray80", "gray20"),
    max.words = 100, random.order = F
  )
```

### Analyse de sentiment

L'analyse de sentiment consiste √† analyser les √©motions contenues dans un texte (joie, tristesse etc...). Je rep√®tes qu'√† ce niveau une expertise est hautement souhaitable. Nous pr√©sentons ici une introduction ainsi qu'une mise en oeuvre pratique en utilisant R. Nous allons nous servir de la base de donn√©es contenue dans rfeel qui reprend les six [√©motions](https://fr.wikipedia.org/wiki/Paul_Ekman) selon Ekman.

```{r}

sentiment <- c(
  "Joie", "Surprise", "D√©go√ªt", "Tristesse", "Peur",
  "Col√®re"
)
dop_speech_clean %>%
  inner_join(x = ., y = rfeel("score")) %>%
  group_by(sentiment) %>%
  summarise(freq = n()) %>%
  ungroup() %>%
  mutate(sentiment = reorder(sentiment, freq)) %>%
  ggplot(data = ., mapping = aes(x = sentiment, y = freq, fill = sentiment)) +
  geom_col() +
  scale_x_discrete(label = sentiment) +
  scale_fill_viridis_d(option = "F", direction = -1) +
  coord_flip() +
  theme(
    legend.position = "none",
    plot.title.position = "plot"
  ) +
  labs(
    title = "Discours d'Orientation Politique : les √©motions v√©hicul√©es",
    subtitle = "Thomas Sankara | Octobre 1983",
    caption = "¬© Data Science avec R, 2021",
    x = NULL, y = "# Nombre"
  )
```

Le DOP d'Octobre 1983 d√©gageait plus de la col√®re ?

## Conclusion

Comme nous l'avons dit en introduction, le Text Mining regorge bien de techniques avanc√©es comme la classification de texte, des algorithmes d'apprentissage supervis√© et j'en passe. Cet article avait pour but d'introduire quelque notions et de susciter un int√©r√™t sur la question.

## Ressources

Pour en apprendre plus veuillez consulter ses ressources.

-   [Text Mining with R : A Tidy Approach](https://www.tidytextmining.com/index.html)

-   [Text Analysis in R](https://m-clark.github.io/text-analysis-with-R/)

-   [Supervised Machine Learning for Text Analysis in R](https://smltar.com)

## Ref√©rences

Colin Fay (2019). proustr: Tools for Natural Language Processing in French. R package version 0.4.0. <https://CRAN.R-project.org/package=proustr>

Colin Fay (2021). rfeel: Access the FEEL Lexicon. R package version 0.0.0.9000. <https://github.com/ColinFay/rfeel>

Erich Neuwirth (2014). RColorBrewer: ColorBrewer Palettes. R package version 1.1-2. <https://CRAN.R-project.org/package=RColorBrewer>

H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.

Hadley Wickham (2007). Reshaping Data with the reshape Package. Journal of Statistical Software, 21(12), 1-20. URL <http://www.jstatsoft.org/v21/i12/.>

Hadley Wickham (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.4.0. <https://CRAN.R-project.org/package=stringr>

Hadley Wickham (2021). forcats: Tools for Working with Categorical Variables (Factors). R package version 0.5.1. <https://CRAN.R-project.org/package=forcats>

Hadley Wickham (2021). tidyr: Tidy Messy Data. R package version 1.1.4. <https://CRAN.R-project.org/package=tidyr>

Hadley Wickham and Jim Hester (2021). readr: Read Rectangular Text Data. R package version 2.1.0. <https://CRAN.R-project.org/package=readr>

Hadley Wickham, Romain Fran√ßois, Lionel Henry and Kirill M√ºller (2021). dplyr: A Grammar of Data Manipulation. R package version 1.0.7. <https://CRAN.R-project.org/package=dplyr>

Ian Fellows (2018). wordcloud: Word Clouds. R package version 2.6. <https://CRAN.R-project.org/package=wordcloud>

Kau√™ de Sousa and Adam H. Sparks and William Ashmall and Jacob van Etten and Svein √ò. Solberg (2020). chirps: API Client for the CHIRPS Precipitation Data in R. Journal of Open Source Software, 5(51), 2419, <https://doi.org/10.21105/joss.02419>

Kirill M√ºller and Hadley Wickham (2021). tibble: Simple Data Frames. R package version 3.1.6. <https://CRAN.R-project.org/package=tibble>

Lionel Henry and Hadley Wickham (2020). purrr: Functional Programming Tools. R package version 0.3.4. <https://CRAN.R-project.org/package=purrr>

Makowski, D., Ben-Shachar, M.S., Patil, I. & L√ºdecke, D. (2020). Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption. CRAN. Available from <https://github.com/easystats/report.> doi: .

Matthew Lincoln (2020). clipr: Read and Write from the System Clipboard. R package version 0.7.1. <https://CRAN.R-project.org/package=clipr>

Oliver Hawkins (2021). pilot: A minimal ggplot2 theme with an accessible discrete color palette. R package version 3.5.0.

R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL <https://www.R-project.org/.>

Silge J, Robinson D (2016). "tidytext: Text Mining and Analysis Using Tidy Data Principlesin R." \_JOSS\_, \*1\*(3). doi: 10.21105/joss.00037 (URL: [https://doi.org/10.21105/joss.00037),\<URL:](https://doi.org/10.21105/joss.00037),\<URL:) <http://dx.doi.org/10.21105/joss.00037>.

Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, <https://doi.org/10.21105/joss.01686>

Winston Chang, (2014). extrafont: Tools for using fonts. R package version 0.17. <https://CRAN.R-project.org/package=extrafont>
